=== HF to Packing Model Conversion ===
Source:  hf_llava_vit_large_ln
Target:  hf_llava_vit_packing_large_ln
Weights: /video_vit/xiangan/checkpoint_llava_vit/2025_12_02_new_l14_continue_128gpus_how_to_100m_448px_224px_num_frames_16_huggingface/00210000_hf/
Output:  /video_vit/pretrain_models/deepglint/hevc/hevc_vit_packing_12_04_00210000_l14_flash_attn

--> Creating HF Model...

--> Creating Packing Model...
--> Remapping State Dict...
[Remap] Starting state dict remapping from HF to Packing format...
[Remap] Combining Q/K/V into QKV for 24 layers...
--> Loading weights into Packing model...
    Load OK (No critical missing keys).

--> Moving models to cuda and casting to bfloat16...

--> Fetching real image for verification (448x448)...
--> Downloading real image from http://images.cocodataset.org/val2017/000000039769.jpg (Target Size: 448)...

=== Verifying Consistency with Packing Model (grid_thw input - bfloat16) ===
    Running on Device: cuda:0
    Model Dtype: torch.bfloat16
    Input Shape: torch.Size([1, 3, 448, 448]) | Dtype: torch.bfloat16
    Patch Size: 14
    grid_thw: tensor([[ 1, 32, 32]], device='cuda:0')
    Packing input shape: torch.Size([1024, 588]) (seq_len=1024, patch_dim=588)
    patch_positions shape: torch.Size([1024, 3])
    [Packing Feature] Max Diff:       2.136719
    [Packing Feature] Min Cosine Sim: -0.05994046 (Mean: 0.99665511)
    ❌ Packing Feature: FAIL
    [Packing Head]    Max Diff:       0.007812
    [Packing Head]    Min Cosine Sim: 0.99996728 (Mean: 0.99996728)
    ✅ Packing Head:    PASS

=== Verifying Video Consistency with Packing Model (8 frames - bfloat16) ===
    Running on Device: cuda:0
    Model Dtype: torch.bfloat16
    Video Input Shape: torch.Size([1, 3, 8, 224, 224]) (B, C, T, H, W)
    Original frame indices: [0, 1, 2, 3, 4, 5, 6, 7]
    Interpolated indices (in 64-frame context): [0, 9, 18, 27, 36, 45, 54, 63]
    Padded video shape: torch.Size([1, 3, 64, 224, 224])
    visible_index shape: torch.Size([1, 2048])
    Packing input shape: torch.Size([2048, 588])
    patch_positions shape: torch.Size([2048, 3])
    grid_thw: [[8, 16, 16]]
    [Video Packing Feature] Max Diff:       3.335205
    [Video Packing Feature] Min Cosine Sim: -0.02298299 (Mean: 0.99482334)
    ❌ Video Packing Feature: FAIL
    [Video Packing Head]    Max Diff:       0.015625
    [Video Packing Head]    Min Cosine Sim: 0.99996185 (Mean: 0.99996185)
    ✅ Video Packing Head:    PASS

=== Verifying Mixed Video+Image Consistency (8 frames + image - bfloat16) ===
    Running on Device: cuda:0
    Video Input Shape: torch.Size([1, 3, 8, 224, 224])
    Image Input Shape: torch.Size([1, 3, 448, 448])
    Combined input shape: torch.Size([3072, 588])

    --- Video Comparison ---
    [Mixed Video] Min Cosine Sim: -0.02298299 (Mean: 0.99482334)
    ❌ Mixed Video Feature: FAIL

    --- Image Comparison ---
    [Mixed Image] Min Cosine Sim: 0.51247108 (Mean: 0.99776947)
    ❌ Mixed Image Feature: FAIL

    --- Overall Summary ---
    ❌ Mixed Video+Image Consistency: SOME FAILED

=== Verifying Multi-Sample Consistency (3 images + 2 videos - bfloat16) ===
    Image resolutions: [224, 336, 1008]
    Video resolutions: [378, 518]
    Combined input shape: torch.Size([22800, 588])
    [Image 1 (res=224)] Min Cos: 0.17416318
    [Image 2 (res=336)] Min Cos: 0.55914819
    [Image 3 (res=1008)] Min Cos: 0.26605725
    [Video 1 (res=378)] Min Cos: -0.11095463
    [Video 2 (res=518)] Min Cos: 0.09236584
    ❌ Multi-Sample Consistency: SOME FAILED

--> Saving Packing Model to /video_vit/pretrain_models/deepglint/hevc/hevc_vit_packing_12_04_00210000_l14_flash_attn...
    Saving CLIPImageProcessor config...
✅ Packing Model (bf16) and CLIP Processor saved.

=== Verifying Loaded Saved Packing Model ===
--> Loading from: /video_vit/pretrain_models/deepglint/hevc/hevc_vit_packing_12_04_00210000_l14_flash_attn
    Loading Image Processor...
    Loading Vision Tower (LlavaViTPackingModel) with torch_dtype=bfloat16...
    ✅ Successfully loaded model
    [Reloaded Model] Min Cosine Sim: 0.53825361
    ❌ Reloaded Model Verification: FAIL
